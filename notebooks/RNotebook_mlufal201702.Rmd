---
title: "Machine Learning Project - UFAL 2017.2"
output: html_notebook
---

O Objetivo geral do estudo é gerar um modelo de predição capaz de detectar bugs em alterações de códigos na linguagem C. 

O Dataset contém metricas de software coletadas via [API Understand] (https://scitools.com/feature/metrics/) de Funções sem bugs de projetos open source presentes no Github escrito na linguagem C.

####Projetos Utilizados:
- [Glibc](https://github.com/lattera/glibc) - The GNU C Library is the standard system C library for all GNU systems
- [Httpd](https://github.com/apache/httpd) - Web Server
- [Kernel](https://github.com/torvalds/linux) - Kernel Linux
- [OpenVPN](https://github.com/mozilla/openvpn) - Mozilla OpenVPN
- [Xen](https://github.com/xen-project/xen) - Virtual Machine Monitor (VMM)

Descrição do Dataset:


```{r, echo=FALSE}
input_sample <- read.csv(file = "/home/r4ph/R/machine-learning-ufal/datasets/vulnerability/balanced/glibc_data_balanced.csv", stringsAsFactors = FALSE)
head(input_sample)

```


Importando Packages de Machine Learning:

```{r}
library(RWeka)
library(e1071)
library(gmodels)
library(C50)
library(caret)
library(irr)
library(randomForest)
library(mlr)
library(evaluate)
library(FSelector)
```

Funções para Calcular a [Efetividade](https://en.wikipedia.org/wiki/Precision_and_recall) do Modelo Baseado em [K-fold Cross Validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics))

  
```{r}

# Function to calculate precision
precision <- function(tp, fp) {
  precision <- tp / (tp + fp)
  
  return(precision)
}

# Function to calculate recall
recall <- function(tp, fn) {
  recall <- tp / (tp + fn)
  
  return(recall)
}

# Function to calculate F-measure
f_measure <- function(tp, fp, fn) {
  f_measure <-
    (2 * precision(tp, fp) * recall(tp, fn)) / (recall(tp, fn) + precision(tp, fp))
  
  return(f_measure)
}

# Function to calculate true_positive, true_negative, false_positive, false_negative
measures <- function(test, pred) {
  true_positive <- 0
  true_negative <- 0
  false_positive <- 0
  false_negative <- 0
  
  for (i in 1:length(pred)) {
    if (test[i] == 'VULNERABLE' && pred[i] == 'VULNERABLE') {
      true_positive <- true_positive + 1
    } else if (test[i] == 'NEUTRAL' && pred[i] == 'NEUTRAL') {
      true_negative <- true_negative + 1
    } else if (test[i] == 'NEUTRAL' && pred[i] == 'VULNERABLE') {
      false_negative <- false_negative + 1
    } else if (test[i] == 'VULNERABLE' && pred[i] == 'NEUTRAL') {
      false_positive <- false_positive + 1
    }
  }
  
  measures <-
    c(
      precision(true_positive, false_positive),
      recall(true_positive, false_negative),
      f_measure(true_positive, false_positive, false_negative)
    )
  
  return(measures)
}
```

###Algoritmos e Técnicas de Machine Learning Utilizadas no Projeto:
- J48[Arvore de Decisão]
- NaiveBayes 
- SVM
- OneR [Regras]
- RandomForest [Arvores de Decisão]
- C50 [Arvore de Decisão]

As funções abaixo realizam o treinamento (train) e testes do nosso modelo (model) de detecção de bugs baseados em Metricas de Software. Lembrando que o treinamento e testes são utilizadas as técnicas de K-fold cross validation com 10 folds e calculo da efetividade.

```{r}

# Techiniques
executeJ48 <- function(dataset, folds) {
  results <- lapply(folds, function(x) {
    train <- dataset[-x,]
    test <- dataset[x,]
    model <- J48(train$Affected ~ ., data = train)
    pred <- predict(model, test)
    results <- measures(test$Affected, pred)
    
    return(results)
  })
  
}

executeNaiveBayes <- function(dataset, folds) {
  results <- lapply(folds, function(x) {
    train <- dataset[-x,]
    test <- dataset[x,]
    model <- naiveBayes(train, train$Affected, laplace = 1)
    pred <- predict(model, test)
    
    results <- measures(test$Affected, pred)
    
    return(results)
  })
  
}

executeSVM <- function(dataset, folds) {
  results <- lapply(folds, function(x) {
    train <- dataset[-x, ]
    test <- dataset[x, ]
    model <- svm(train$Affected ~ ., data = train)
    pred <- predict(model, test)
    
    results <- measures(test$Affected, pred)
    
    return(results)
  })
  
}

executeOneR <- function(dataset, folds) {
  results <- lapply(folds, function(x) {
    train <- dataset[-x, ]
    test <- dataset[x, ]
    model <- OneR(train$Affected ~ ., data = train)
    pred <- predict(model, test)
    
    results <- measures(test$Affected, pred)
    
    return(results)
  })
  
}


executeRandomForest <- function(dataset, folds) {
  results <- lapply(folds, function(x) {
    train <- dataset[-x, ]
    test <- dataset[x, ]
    model <- randomForest(train$Affected ~ ., data = train)
    pred <- predict(model, test)
    
    results <- measures(test$Affected, pred)
    
    return(results)
  })
}


executeC50 <- function(dataset, folds) {
  results <- lapply(folds, function(x) {
    train <- dataset[-x, ]
    test <- dataset[x, ]
    model <- C5.0(train$Affected ~ ., data = train)
    pred <- predict(model, test)
    results <- measures(test$Affected, pred)
    return(results)
  })
  
}
```

###Seleção de Features:

Aqui é realizada uma tarefa de classificação dos valores individuais de cada feature. Tais valores estão relacionados ao seu grau de importância de acordo com o método escolhido. Os Métodos escolhidos foram:

- Chi Squared
- Information Gain

Através da Tabela abaixo é possiveis visualizar os valores de cada feature dentro do dataset:

```{r}
features <- makeClassifTask(id = deparse(substitute(input_sample)), input_sample, colnames(input_sample)[28] )
featuresSelection = generateFilterValuesData(features, method = c("information.gain", "chi.squared"))
featuresSelection$data
```

Abaixo é possivel avaliar a distribuição dos valores dos métodos de seleção de features utilizadas gerando seus respectivos bloxplots:

```{r}
par(mfrow=c(1,2))
for(i in 3:4) {
	boxplot(featuresSelection$data[i], main=names(featuresSelection$data)[i])
}
```

Essa distribuição também pode ser avaliada através de barplots, onde o eixo x corresponde as features utilizadas no dataset e o eixo y ao seu grau de importância respectivamente. Como pode ser visto as features AltCountLineCode e CountLineCode tiveram resultados melhores que as demais.

```{r}
plotFilterValues(featuresSelection)
```

Através da função generateFilterValuesData é possível manter somente as Features com um grau/valor de importância acima de 0.2 do método de Informação de Ganho. Esses valores podem ser filtrados por thresholds, percentuais e ranking.


```{r}
fv = generateFilterValuesData(features, method = "information.gain")
filtered = filterFeatures(features, fval = fv, threshold = 0.2)
filtered
```


###Balanceamento dos Dados:

Temos abaixo uma gráfico contendo a distribuição das classes do dois tipos de conjunto de dados.

- Balanceado: Nesse conjunto o numero de classes são iguais, ou seja, temos as mesma quantidade de linhas de metricas de softwares de funções com bugs e sem bugs respectivamente.
- Não Balanceado: Já no conjunto não balanceado, normalmente o comportamento é de ter menos bugs ems funções de código em C nos projetos utilizados.

Este problema é predominante em cenários onde a detecção de anomalias é crucial, como transações fraudulentas nos bancos, identificação de doenças raras, etc. Nessa situação, o modelo preditivo desenvolvido com algoritmos de aprendizado convencional pode ser tendencioso e impreciso. 


```{r}
input_balanced <- read.csv(file = "/home/r4ph/R/machine-learning-ufal/datasets/vulnerability/balanced/glibc_data_balanced.csv", stringsAsFactors = FALSE)
input_unbalanced <- read.csv(file = "/home/r4ph/R/machine-learning-ufal/datasets/vulnerability/unbalanced/glibc_data.csv", stringsAsFactors = FALSE)
# Criando Histogramas
par(mfrow=c(1,2))
barplot(table(input_balanced$Affected), main = "Balanced")
barplot(table(input_unbalanced$Affected), main = "Unbalanced")


```

Trecho responsável pela execução dos algoritmos de machine learning para os 5 projetos utilizando as técnicas supracitadas.

```{r}
filenames = list.files(path = "/home/r4ph/R/machine-learning-ufal/datasets/vulnerability/balanced",
                       full.names = TRUE,
                       recursive = TRUE)

projects <- c("GlibC", "Httpd", "Kernel", "Mozilla", "Xen")
setwd("/home/r4ph/R/machine-learning-ufal/datasets/vulnerability/results/")

#Create data frame:
createDf()

#Apply Results Balanced
for (i in 1:length(filenames)) {
  
  cat("Writting ")
  dataset <- read.csv(filenames[i])
  #project <- strsplit(filenames, split = '/')[[i]][9]
  folds <- createFolds(dataset[1:27], k = 10, returnTrain = TRUE)
  
  rows <- nrow(dataset)
  cat(paste0("Input: ", rows, " rows in project... ", projects[i], "\n"))
  
  #Results C50
  finalResults(executeC50(dataset, folds), projects[i], "C50")
  #Results Bayes
  finalResults(executeNaiveBayes(dataset, folds), projects[i], "NaiveBayes")
  #Algorithm SVM
  finalResults(executeSVM(dataset, folds), projects[i], "SVM")
  #Jr48
  finalResults(executeJ48(dataset, folds), projects[i], "Jr48")
  #OneR
  finalResults(executeOneR(dataset, folds), projects[i], "OneR")
  #RandomForest
  finalResults(executeRandomForest(dataset, folds), projects[i], "RandomForest")
  
}

```



###Resultados Alcançados

####Tabelas:

```{r}
resultsUnbal <- read.csv(file = "/home/r4ph/R/machine-learning-ufal/datasets/vulnerability/results/ml_balanced.csv", stringsAsFactors = FALSE)
resultsUnbal
```

####Plots:

```{r}
ggplot(resultsUnbal) +
  geom_bar(aes(x = Algorithm, y = F.Measure, fill = Project, group = Project), position = "dodge", stat = "identity") +
  geom_text( aes(x = Algorithm, y = F.Measure, label = round(F.Measure,2), group = Project),  
             check_overlap = TRUE, position = position_dodge(width = 1), vjust = -0.5, size = 2) + #scale_fill_grey() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(legend.position= c(0.85, 0.95), legend.direction="horizontal", legend.title = element_blank(), 
        axis.title.x=element_blank(), legend.text=element_text(size=5), legend.background = element_rect(fill = "transparent", colour = NA) ) +
  theme(panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank(),
        plot.background = element_rect(fill = "transparent", colour = NA))
```

Citar Literaruta (Revisão de Literatura)
